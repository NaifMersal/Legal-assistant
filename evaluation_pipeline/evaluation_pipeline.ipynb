{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed0859f1",
      "metadata": {
        "id": "ed0859f1"
      },
      "source": [
        "# Information Retrieval Evaluation Pipeline\n",
        "\n",
        "This notebook implements a comprehensive evaluation pipeline for information retrieval systems using FAISS indices and BGE-M3 embeddings. The pipeline includes:\n",
        "- Retrieval evaluation with multiple metrics\n",
        "- Visualization of results\n",
        "- Detailed performance analysis by categories\n",
        "- Report generation\n",
        "\n",
        "First, let's set up our environment and install required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d6c1dd2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6c1dd2c",
        "outputId": "c9224c24-645d-4983-8450-197720b99b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers sentence-transformers rank_bm25 nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a853bc3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a853bc3d",
        "outputId": "a86392ba-2419-4690-801e-e258f1a811e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting FlagEmbedding\n",
            "  Downloading FlagEmbedding-1.3.5.tar.gz (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (4.57.1)\n",
            "Requirement already satisfied: datasets>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (4.0.0)\n",
            "Requirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (1.11.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (5.1.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (0.17.1)\n",
            "Collecting ir-datasets (from FlagEmbedding)\n",
            "  Downloading ir_datasets-0.5.11-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from FlagEmbedding) (5.29.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (0.35.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.19.0->FlagEmbedding) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (2025.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.44.2->FlagEmbedding) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.44.2->FlagEmbedding) (0.22.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (4.13.5)\n",
            "Collecting inscriptis>=2.2.0 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.12/dist-packages (from ir-datasets->FlagEmbedding) (5.4.0)\n",
            "Collecting trec-car-tools>=2.5.4 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
            "Collecting lz4>=3.1.10 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting warc3-wet>=0.2.3 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zlib-state>=0.1.3 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading zlib_state-0.1.10-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting ijson>=3.1.3 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting unlzw3>=0.2.1 (from ir-datasets->FlagEmbedding)\n",
            "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence_transformers->FlagEmbedding) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence_transformers->FlagEmbedding) (1.16.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding) (2.8)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (3.13.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.20.1->FlagEmbedding) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.6.0->FlagEmbedding) (1.3.0)\n",
            "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding)\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.6.0->FlagEmbedding) (3.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (1.22.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ir_datasets-0.5.11-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.1/866.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
            "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
            "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
            "Downloading zlib_state-0.1.10-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Building wheels for collected packages: FlagEmbedding, warc3-wet-clueweb09, cbor\n",
            "  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FlagEmbedding: filename=FlagEmbedding-1.3.5-py3-none-any.whl size=233746 sha256=48d92b3d7b15e65788e208350e3d3d36657a96a0c34f0da79b3d3f59f4caf10d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/1f/f6/78f862bb80cb959cc9960b7c4e2d1f702b1bc0e79d19b5f124\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=7efafa4535507e8e4c479686fe3e871a1db14f66c7587e613146f7e23e4cfd3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/85/c2/9f0f621def52a1d5db7d29984f81e45f9fb6dfeb1a4eb6e31c\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp312-cp312-linux_x86_64.whl size=55022 sha256=da29596875b340197fbd5af2b4f27abc7b3f0319c3256d4a4d530d0225741213\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/3e/21/a739cbcc331a1ab45c326d6edbdac6118de4402f6076e30ff1\n",
            "Successfully built FlagEmbedding warc3-wet-clueweb09 cbor\n",
            "Installing collected packages: warc3-wet-clueweb09, warc3-wet, cbor, zlib-state, unlzw3, trec-car-tools, lz4, ijson, faiss-cpu, inscriptis, ir-datasets, FlagEmbedding\n",
            "Successfully installed FlagEmbedding-1.3.5 cbor-1.0.0 faiss-cpu-1.12.0 ijson-3.4.0.post0 inscriptis-2.6.0 ir-datasets-0.5.11 lz4-4.4.4 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.10\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu FlagEmbedding tqdm numpy matplotlib seaborn\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba0af75b",
      "metadata": {
        "id": "ba0af75b"
      },
      "source": [
        "## Import Required Libraries\n",
        "\n",
        "Let's import all the necessary Python libraries and configure the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cea97f7c",
      "metadata": {
        "id": "cea97f7c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import multiprocessing\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "import faiss\n",
        "faiss.omp_set_num_threads(1)\n",
        "\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Any\n",
        "from dataclasses import dataclass\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dd92f57",
      "metadata": {
        "id": "2dd92f57"
      },
      "source": [
        "## Define Data Classes and Helper Functions\n",
        "\n",
        "First, let's define our evaluation metrics dataclass and implement the core evaluation class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eebc15ff",
      "metadata": {
        "id": "eebc15ff"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class EvaluationMetrics:\n",
        "    recall_at_k: Dict[int, float]\n",
        "    precision_at_k: Dict[int, float]\n",
        "    mrr: float\n",
        "    map_score: float\n",
        "    ndcg_at_k: Dict[int, float]\n",
        "    hit_rate_at_k: Dict[int, float]\n",
        "\n",
        "class RetrievalEvaluator:\n",
        "    def __init__(self,\n",
        "                 faiss_index_path: str,\n",
        "                 qa_dataset_path: str,\n",
        "                 documents_path: str,\n",
        "                 embeddings_model=None,\n",
        "                 k_values: List[int] = [1, 3, 5, 10, 20],\n",
        "                 metric_type: str = 'ip',\n",
        "                 use_hybrid: bool = False,\n",
        "                 hybrid_weights: Tuple[float, float] = (0.7, 0.3)):\n",
        "\n",
        "        self.k_values = k_values\n",
        "        self.index = faiss.read_index(faiss_index_path)\n",
        "        self.embeddings_model = embeddings_model\n",
        "        self.metric_type = metric_type.lower()\n",
        "        self.use_hybrid = use_hybrid\n",
        "        self.dense_weight, self.sparse_weight = hybrid_weights\n",
        "\n",
        "        if self.metric_type not in ['ip', 'l2']:\n",
        "            raise ValueError(\"metric_type must be either 'ip' or 'l2'\")\n",
        "        print(\"Loading QA dataset...\")\n",
        "        with open(qa_dataset_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "            self.qa_pairs = data.get('qa_pairs', [])\n",
        "            self.metadata = data.get('metadata', {})\n",
        "\n",
        "        print(f\"Loaded {len(self.qa_pairs)} QA pairs\")\n",
        "        print(f\"Loading documents from {documents_path}...\")\n",
        "        self.doc_texts = {}\n",
        "        doc_id_counter = 0\n",
        "\n",
        "        with open(documents_path, 'r', encoding='utf-8') as f:\n",
        "            docs_data = json.load(f)\n",
        "            if isinstance(docs_data, dict):\n",
        "                for category, subcats in docs_data.items():\n",
        "                    if isinstance(subcats, dict):\n",
        "                        for subcat, systems in subcats.items():\n",
        "                            if isinstance(systems, dict):\n",
        "                                for system_name, system_data in systems.items():\n",
        "                                    if isinstance(system_data, dict):\n",
        "                                        parts = system_data.get('parts', {})\n",
        "                                        if isinstance(parts, dict):\n",
        "                                            for part_name, articles in parts.items():\n",
        "                                                if isinstance(articles, list):\n",
        "                                                    for article in articles:\n",
        "                                                        if isinstance(article, dict):\n",
        "                                                            article_id = article.get('id', doc_id_counter)\n",
        "                                                            article_text = article.get('Article_Text', '')\n",
        "                                                            article_title = article.get('Article_Title', '')\n",
        "\n",
        "                                                            full_text = f\"{article_title}\\n{article_text}\".strip()\n",
        "\n",
        "                                                            if full_text:\n",
        "                                                                self.doc_texts[article_id] = full_text\n",
        "                                                                doc_id_counter += 1\n",
        "\n",
        "        if not self.doc_texts:\n",
        "            raise ValueError(f\"No documents found in {documents_path}! Could not extract articles from nested structure.\")\n",
        "\n",
        "        print(f\"Loaded {len(self.doc_texts)} documents from nested structure\")\n",
        "\n",
        "\n",
        "        if self.use_hybrid:\n",
        "            print(\"Initializing BM25 for hybrid retrieval...\")\n",
        "            from rank_bm25 import BM25Okapi\n",
        "            from nltk.tokenize import word_tokenize\n",
        "            import nltk\n",
        "            nltk.download('punkt', quiet=True)\n",
        "\n",
        "\n",
        "            self.doc_ids = sorted(self.doc_texts.keys())\n",
        "            self.corpus = [self.doc_texts[doc_id] for doc_id in self.doc_ids]\n",
        "\n",
        "            print(f\"Tokenizing {len(self.corpus)} documents for BM25...\")\n",
        "            self.tokenized_corpus = [word_tokenize(doc.lower()) for doc in self.corpus]\n",
        "\n",
        "            if not self.tokenized_corpus:\n",
        "                raise ValueError(\"No documents available for BM25 indexing!\")\n",
        "\n",
        "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
        "            print(\"BM25 initialization complete!\")\n",
        "\n",
        "        print(f\"Evaluator initialized successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ec719c97",
      "metadata": {
        "id": "ec719c97"
      },
      "outputs": [],
      "source": [
        "def embed_query(self, query: str) -> np.ndarray:\n",
        "    \"\"\"Generate embedding for a query using BGE-M3\"\"\"\n",
        "    if self.embeddings_model is None:\n",
        "        raise ValueError(\"Embeddings model not provided\")\n",
        "\n",
        "    embedding_dict = self.embeddings_model.encode([query])\n",
        "    embedding = np.array(embedding_dict[\"dense_vecs\"], dtype='float32')\n",
        "\n",
        "    if len(embedding.shape) == 1:\n",
        "        embedding = embedding.reshape(1, -1)\n",
        "\n",
        "    if self.metric_type == 'ip':\n",
        "        embedding = embedding / np.linalg.norm(embedding, axis=1, keepdims=True)\n",
        "\n",
        "    return embedding\n",
        "\n",
        "def min_max_normalize(self, scores: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Apply min-max normalization to scores\"\"\"\n",
        "    if len(scores) == 0:\n",
        "        return scores\n",
        "    min_score = np.min(scores)\n",
        "    max_score = np.max(scores)\n",
        "    if max_score == min_score:\n",
        "        return np.ones_like(scores)\n",
        "    return (scores - min_score) / (max_score - min_score)\n",
        "\n",
        "def hybrid_search(self, query: str, k: int = 10) -> Tuple[List[int], List[float]]:\n",
        "    \"\"\"Perform hybrid search combining dense and sparse retrieval\"\"\"\n",
        "    from nltk.tokenize import word_tokenize\n",
        "\n",
        "    query_embedding = self.embed_query(query)\n",
        "    if len(query_embedding.shape) == 1:\n",
        "        query_embedding = query_embedding.reshape(1, -1)\n",
        "\n",
        "    dense_distances, dense_indices = self.index.search(query_embedding, k)\n",
        "    dense_scores = dense_distances[0]\n",
        "\n",
        "    tokenized_query = word_tokenize(query.lower())\n",
        "    sparse_scores = self.bm25.get_scores(tokenized_query)\n",
        "\n",
        "    if self.metric_type == 'l2':\n",
        "        dense_scores = 1.0 / (1.0 + dense_scores)\n",
        "\n",
        "    dense_scores = self.min_max_normalize(dense_scores)\n",
        "    sparse_scores = self.min_max_normalize(sparse_scores)\n",
        "\n",
        "    final_scores = []\n",
        "    final_ids = []\n",
        "    seen_ids = set()\n",
        "\n",
        "    for idx, score in zip(dense_indices[0], dense_scores):\n",
        "        doc_id = idx\n",
        "        if doc_id not in seen_ids:\n",
        "            seen_ids.add(doc_id)\n",
        "            combined_score = (self.dense_weight * score +\n",
        "                            self.sparse_weight * sparse_scores[doc_id])\n",
        "            final_scores.append(combined_score)\n",
        "            final_ids.append(doc_id)\n",
        "\n",
        "    final_scores = self.min_max_normalize(np.array(final_scores))\n",
        "\n",
        "    sorted_pairs = sorted(zip(final_ids, final_scores),\n",
        "                         key=lambda x: x[1], reverse=True)\n",
        "    final_ids, final_scores = zip(*sorted_pairs)\n",
        "\n",
        "    return list(final_ids)[:k], list(final_scores)[:k]\n",
        "\n",
        "def retrieve(self, query: str, k: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Retrieve top-k documents for a query\"\"\"\n",
        "    if self.use_hybrid:\n",
        "        retrieved_ids, scores = self.hybrid_search(query, k=k)\n",
        "        scores = np.array(scores)\n",
        "        indices = np.array(retrieved_ids)\n",
        "    else:\n",
        "        query_embedding = self.embed_query(query)\n",
        "        if len(query_embedding.shape) == 1:\n",
        "            query_embedding = query_embedding.reshape(1, -1)\n",
        "\n",
        "        distances, indices = self.index.search(query_embedding, k)\n",
        "\n",
        "        if self.metric_type == 'l2':\n",
        "            scores = 1.0 / (1.0 + distances[0])\n",
        "            scores = self.min_max_normalize(scores)\n",
        "        else:\n",
        "            scores = (distances[0] + 1) / 2\n",
        "            scores = self.min_max_normalize(scores)\n",
        "\n",
        "    return scores, indices\n",
        "\n",
        "RetrievalEvaluator.embed_query = embed_query\n",
        "RetrievalEvaluator.min_max_normalize = min_max_normalize\n",
        "RetrievalEvaluator.hybrid_search = hybrid_search\n",
        "RetrievalEvaluator.retrieve = retrieve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "57f91bb3",
      "metadata": {
        "id": "57f91bb3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_recall_at_k(self, retrieved_ids: List[int], relevant_ids: List[int], k: int) -> float:\n",
        "    \"\"\"Calculate Recall@k\"\"\"\n",
        "    if not relevant_ids:\n",
        "        return 0.0\n",
        "    retrieved_k = set(retrieved_ids[:k])\n",
        "    relevant_set = set(relevant_ids)\n",
        "    hits = len(retrieved_k.intersection(relevant_set))\n",
        "    return hits / len(relevant_set)\n",
        "\n",
        "def calculate_precision_at_k(self, retrieved_ids: List[int], relevant_ids: List[int], k: int) -> float:\n",
        "    \"\"\"Calculate Precision@k\"\"\"\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    retrieved_k = set(retrieved_ids[:k])\n",
        "    relevant_set = set(relevant_ids)\n",
        "    hits = len(retrieved_k.intersection(relevant_set))\n",
        "    return hits / k\n",
        "\n",
        "def calculate_reciprocal_rank(self, retrieved_ids: List[int], relevant_ids: List[int]) -> float:\n",
        "    \"\"\"Calculate Reciprocal Rank\"\"\"\n",
        "    relevant_set = set(relevant_ids)\n",
        "    for rank, doc_id in enumerate(retrieved_ids, 1):\n",
        "        if doc_id in relevant_set:\n",
        "            return 1.0 / rank\n",
        "    return 0.0\n",
        "\n",
        "def calculate_average_precision(self, retrieved_ids: List[int], relevant_ids: List[int]) -> float:\n",
        "    \"\"\"Calculate Average Precision\"\"\"\n",
        "    if not relevant_ids:\n",
        "        return 0.0\n",
        "    relevant_set = set(relevant_ids)\n",
        "    precision_sum = 0.0\n",
        "    hits = 0\n",
        "    for rank, doc_id in enumerate(retrieved_ids, 1):\n",
        "        if doc_id in relevant_set:\n",
        "            hits += 1\n",
        "            precision_sum += hits / rank\n",
        "    return precision_sum / len(relevant_set) if relevant_set else 0.0\n",
        "\n",
        "def calculate_ndcg_at_k(self, retrieved_ids: List[int], relevant_ids: List[int], k: int) -> float:\n",
        "    \"\"\"Calculate NDCG@k\"\"\"\n",
        "    def dcg(relevances, k):\n",
        "        relevances = relevances[:k]\n",
        "        return sum(rel / np.log2(idx + 2) for idx, rel in enumerate(relevances))\n",
        "\n",
        "    retrieved_k = retrieved_ids[:k]\n",
        "    relevances = [1 if doc_id in relevant_ids else 0 for doc_id in retrieved_k]\n",
        "    dcg_score = dcg(relevances, k)\n",
        "    ideal_relevances = [1] * min(len(relevant_ids), k)\n",
        "    idcg_score = dcg(ideal_relevances, k)\n",
        "    return dcg_score / idcg_score if idcg_score > 0 else 0.0\n",
        "\n",
        "def calculate_hit_rate_at_k(self, retrieved_ids: List[int], relevant_ids: List[int], k: int) -> float:\n",
        "    \"\"\"Calculate Hit Rate@k\"\"\"\n",
        "    retrieved_k = set(retrieved_ids[:k])\n",
        "    relevant_set = set(relevant_ids)\n",
        "    return 1.0 if len(retrieved_k.intersection(relevant_set)) > 0 else 0.0\n",
        "\n",
        "\n",
        "RetrievalEvaluator.calculate_recall_at_k = calculate_recall_at_k\n",
        "RetrievalEvaluator.calculate_precision_at_k = calculate_precision_at_k\n",
        "RetrievalEvaluator.calculate_reciprocal_rank = calculate_reciprocal_rank\n",
        "RetrievalEvaluator.calculate_average_precision = calculate_average_precision\n",
        "RetrievalEvaluator.calculate_ndcg_at_k = calculate_ndcg_at_k\n",
        "RetrievalEvaluator.calculate_hit_rate_at_k = calculate_hit_rate_at_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "89d4168e",
      "metadata": {
        "id": "89d4168e"
      },
      "outputs": [],
      "source": [
        "def evaluate_single_query(self, qa_pair: Dict[str, Any], max_k: int = 20) -> Dict[str, Any]:\n",
        "    \"\"\"Evaluate a single query\"\"\"\n",
        "    question = qa_pair['question']\n",
        "    relevant_ids = qa_pair['references_ids']\n",
        "\n",
        "    distances, retrieved_indices = self.retrieve(question, k=max_k)\n",
        "\n",
        "    if self.metric_type == 'l2':\n",
        "        scores = 1.0 / (1.0 + distances)\n",
        "    else:\n",
        "        scores = distances\n",
        "\n",
        "\n",
        "    retrieved_ids = retrieved_indices.flatten().tolist()\n",
        "\n",
        "    results = {\n",
        "        'qa_id': qa_pair['id'],\n",
        "        'question': question,\n",
        "        'relevant_ids': relevant_ids,\n",
        "        'retrieved_ids': retrieved_ids,\n",
        "        'distances': distances.tolist(),\n",
        "        'scores': scores.tolist(),\n",
        "        'metrics': {}\n",
        "    }\n",
        "\n",
        "    for k in self.k_values:\n",
        "        if k <= max_k:\n",
        "            results['metrics'][f'recall@{k}'] = self.calculate_recall_at_k(\n",
        "                retrieved_ids, relevant_ids, k)\n",
        "            results['metrics'][f'precision@{k}'] = self.calculate_precision_at_k(\n",
        "                retrieved_ids, relevant_ids, k)\n",
        "            results['metrics'][f'ndcg@{k}'] = self.calculate_ndcg_at_k(\n",
        "                retrieved_ids, relevant_ids, k)\n",
        "            results['metrics'][f'hit_rate@{k}'] = self.calculate_hit_rate_at_k(\n",
        "                retrieved_ids, relevant_ids, k)\n",
        "\n",
        "    results['metrics']['reciprocal_rank'] = self.calculate_reciprocal_rank(\n",
        "        retrieved_ids, relevant_ids)\n",
        "    results['metrics']['average_precision'] = self.calculate_average_precision(\n",
        "        retrieved_ids, relevant_ids)\n",
        "\n",
        "    return results\n",
        "\n",
        "RetrievalEvaluator.evaluate_single_query = evaluate_single_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "81d11e5f",
      "metadata": {
        "id": "81d11e5f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_all(self, sample_size: int = None, sample_indices_path: str = None) -> Tuple[EvaluationMetrics, List[Dict]]:\n",
        "    \"\"\"Evaluate all queries in the dataset\"\"\"\n",
        "    qa_pairs = self.qa_pairs\n",
        "    if sample_size and sample_size < len(qa_pairs):\n",
        "        import random\n",
        "\n",
        "        if sample_indices_path and os.path.exists(sample_indices_path):\n",
        "            with open(sample_indices_path, 'r') as f:\n",
        "                sample_indices = json.load(f)\n",
        "            qa_pairs = [self.qa_pairs[i] for i in sample_indices]\n",
        "            print(f\"Loaded {len(qa_pairs)} samples from {sample_indices_path}\")\n",
        "        else:\n",
        "            sample_indices = random.sample(range(len(self.qa_pairs)), sample_size)\n",
        "            qa_pairs = [self.qa_pairs[i] for i in sample_indices]\n",
        "            print(f\"Generated {sample_size} random samples\")\n",
        "\n",
        "            if sample_indices_path:\n",
        "                with open(sample_indices_path, 'w') as f:\n",
        "                    json.dump(sample_indices, f)\n",
        "                print(f\"Saved sample indices to {sample_indices_path}\")\n",
        "\n",
        "    detailed_results = []\n",
        "    recall_scores = {k: [] for k in self.k_values}\n",
        "    precision_scores = {k: [] for k in self.k_values}\n",
        "    ndcg_scores = {k: [] for k in self.k_values}\n",
        "    hit_rate_scores = {k: [] for k in self.k_values}\n",
        "    rr_scores = []\n",
        "    ap_scores = []\n",
        "\n",
        "    print(f\"Evaluating {len(qa_pairs)} queries...\")\n",
        "    for qa_pair in tqdm(qa_pairs):\n",
        "        result = self.evaluate_single_query(qa_pair)\n",
        "        detailed_results.append(result)\n",
        "\n",
        "        for k in self.k_values:\n",
        "            recall_scores[k].append(result['metrics'][f'recall@{k}'])\n",
        "            precision_scores[k].append(result['metrics'][f'precision@{k}'])\n",
        "            ndcg_scores[k].append(result['metrics'][f'ndcg@{k}'])\n",
        "            hit_rate_scores[k].append(result['metrics'][f'hit_rate@{k}'])\n",
        "\n",
        "        rr_scores.append(result['metrics']['reciprocal_rank'])\n",
        "        ap_scores.append(result['metrics']['average_precision'])\n",
        "\n",
        "    metrics = EvaluationMetrics(\n",
        "        recall_at_k={k: np.mean(recall_scores[k]) for k in self.k_values},\n",
        "        precision_at_k={k: np.mean(precision_scores[k]) for k in self.k_values},\n",
        "        mrr=np.mean(rr_scores),\n",
        "        map_score=np.mean(ap_scores),\n",
        "        ndcg_at_k={k: np.mean(ndcg_scores[k]) for k in self.k_values},\n",
        "        hit_rate_at_k={k: np.mean(hit_rate_scores[k]) for k in self.k_values}\n",
        "    )\n",
        "\n",
        "    return metrics, detailed_results\n",
        "\n",
        "RetrievalEvaluator.evaluate_all = evaluate_all"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff460b70",
      "metadata": {
        "id": "ff460b70"
      },
      "source": [
        "## Visualization Functions\n",
        "\n",
        "Let's implement functions to visualize our evaluation results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ecb8cc4a",
      "metadata": {
        "id": "ecb8cc4a"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(self, metrics: EvaluationMetrics, save_path: str = None):\n",
        "    \"\"\"Visualize evaluation metrics\"\"\"\n",
        "    plt.style.use('default')\n",
        "    plt.rcParams.update({\n",
        "        'figure.facecolor': 'white',\n",
        "        'axes.facecolor': '#f0f0f0',\n",
        "        'axes.grid': True,\n",
        "        'grid.alpha': 0.3,\n",
        "        'grid.color': '#cccccc',\n",
        "        'axes.spines.top': False,\n",
        "        'axes.spines.right': False,\n",
        "    })\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
        "    fig.suptitle('Retrieval Model Evaluation Metrics', fontsize=20, y=1.02, fontweight='bold')\n",
        "    fig.patch.set_facecolor('white')\n",
        "    for ax in axes.flat:\n",
        "        ax.set_facecolor('#f8f9fa')\n",
        "\n",
        "    line_width = 3\n",
        "    marker_size = 12\n",
        "    font_size = 14\n",
        "    title_size = 18\n",
        "    k_vals = sorted(metrics.recall_at_k.keys())\n",
        "\n",
        "\n",
        "    recall_vals = [metrics.recall_at_k[k] for k in k_vals]\n",
        "    axes[0, 0].plot(k_vals, recall_vals, marker='o', linewidth=line_width,\n",
        "                   markersize=marker_size, color='#2E86C1', label='Recall')\n",
        "    axes[0, 0].set_xlabel('k', fontsize=font_size, fontweight='bold')\n",
        "    axes[0, 0].set_ylabel('Recall@k', fontsize=font_size, fontweight='bold')\n",
        "    axes[0, 0].set_title('Recall@k', fontsize=title_size, pad=20, fontweight='bold')\n",
        "    axes[0, 0].set_ylim(max(0, min(recall_vals) - 0.1), min(1.0, max(recall_vals) + 0.1))\n",
        "    axes[0, 0].legend(fontsize=font_size, loc='lower right')\n",
        "\n",
        "\n",
        "    precision_vals = [metrics.precision_at_k[k] for k in k_vals]\n",
        "    axes[0, 1].plot(k_vals, precision_vals, marker='s', linewidth=line_width,\n",
        "                   markersize=marker_size, color='#E67E22', label='Precision')\n",
        "    axes[0, 1].set_xlabel('k', fontsize=font_size, fontweight='bold')\n",
        "    axes[0, 1].set_ylabel('Precision@k', fontsize=font_size, fontweight='bold')\n",
        "    axes[0, 1].set_title('Precision@k', fontsize=title_size, pad=20, fontweight='bold')\n",
        "    axes[0, 1].set_ylim(max(0, min(precision_vals) - 0.1), min(1.0, max(precision_vals) + 0.1))\n",
        "    axes[0, 1].legend(fontsize=font_size, loc='upper right')\n",
        "\n",
        "\n",
        "    ndcg_vals = [metrics.ndcg_at_k[k] for k in k_vals]\n",
        "    axes[1, 0].plot(k_vals, ndcg_vals, marker='^', linewidth=line_width,\n",
        "                   markersize=marker_size, color='#27AE60', label='NDCG')\n",
        "    axes[1, 0].set_xlabel('k', fontsize=font_size, fontweight='bold')\n",
        "    axes[1, 0].set_ylabel('NDCG@k', fontsize=font_size, fontweight='bold')\n",
        "    axes[1, 0].set_title('NDCG@k', fontsize=title_size, pad=20, fontweight='bold')\n",
        "    axes[1, 0].set_ylim(max(0, min(ndcg_vals) - 0.1), min(1.0, max(ndcg_vals) + 0.1))\n",
        "    axes[1, 0].legend(fontsize=font_size, loc='lower right')\n",
        "\n",
        "\n",
        "    hit_rate_vals = [metrics.hit_rate_at_k[k] for k in k_vals]\n",
        "    axes[1, 1].plot(k_vals, hit_rate_vals, marker='d', linewidth=line_width,\n",
        "                   markersize=marker_size, color='#C0392B', label='Hit Rate')\n",
        "    axes[1, 1].set_xlabel('k', fontsize=font_size, fontweight='bold')\n",
        "    axes[1, 1].set_ylabel('Hit Rate@k', fontsize=font_size, fontweight='bold')\n",
        "    axes[1, 1].set_title('Hit Rate@k', fontsize=title_size, pad=20, fontweight='bold')\n",
        "    axes[1, 1].set_ylim(max(0, min(hit_rate_vals) - 0.1), min(1.0, max(hit_rate_vals) + 0.1))\n",
        "    axes[1, 1].legend(fontsize=font_size, loc='lower right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "    summary = f'Summary Metrics:\\nMRR: {metrics.mrr:.3f}\\nMAP: {metrics.map_score:.3f}'\n",
        "    fig.text(0.92, 0.5, summary, fontsize=14,\n",
        "            bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray'))\n",
        "\n",
        "\n",
        "    for ax in axes.flat:\n",
        "        line = ax.get_lines()[0]\n",
        "        for x, y in zip(line.get_xdata(), line.get_ydata()):\n",
        "            ax.annotate(f'{y:.3f}', (x, y), textcoords=\"offset points\",\n",
        "                      xytext=(0,10), ha='center', fontsize=10)\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "RetrievalEvaluator.plot_metrics = plot_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0db63ab1",
      "metadata": {
        "id": "0db63ab1"
      },
      "source": [
        "## Run Evaluation Pipeline\n",
        "\n",
        "Now let's run the evaluation pipeline. First, we need to:\n",
        "1. Initialize the BGE-M3 model\n",
        "2. Set up paths for the FAISS index and QA dataset\n",
        "3. Create an evaluator instance\n",
        "4. Run the evaluation\n",
        "5. Generate visualizations and reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a984b181",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "a0297636a88043d5bbbdbf553ee8fa50",
            "0112d18c830448e885c062c33eb3a620",
            "f04d039a64b1451fa26978a97922715c",
            "522b147bac6c4763adeb06f181bf73b4",
            "6bb4e8ad89ba47d085108cae8d5dcfd5",
            "1d7337f93bd1433088cf374cdbf85083",
            "a5800e881ca34d09b59a7fa2844864f9",
            "63f6e88da29b474d8d00955aa07030e4",
            "c2cd375ecc9f47e29b72ee076ccf8f7c",
            "4fce852996b94211b25d059ed4845cae",
            "550bd9f29fc54a5ebd05286105dfe087"
          ]
        },
        "id": "a984b181",
        "outputId": "27aa3e9f-bb3a-4c4e-db44-79356d46fca9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0297636a88043d5bbbdbf553ee8fa50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using IP metric with index: /content/drive/MyDrive/m3_legal_faiss.index\n",
            "Loading QA dataset...\n",
            "Loaded 4156 QA pairs\n",
            "Loading documents from /content/drive/MyDrive/saudi_laws_scraped.json...\n",
            "Loaded 16371 documents from nested structure\n",
            "Evaluator initialized successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading QA dataset...\n",
            "Loaded 4156 QA pairs\n",
            "Loading documents from /content/drive/MyDrive/saudi_laws_scraped.json...\n",
            "Loaded 16371 documents from nested structure\n",
            "Initializing BM25 for hybrid retrieval...\n",
            "Tokenizing 16371 documents for BM25...\n",
            "BM25 initialization complete!\n",
            "Evaluator initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "from FlagEmbedding import BGEM3FlagModel\n",
        "retriever_model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
        "\n",
        "\n",
        "metric_type = 'ip'\n",
        "metric_suffix = 'V2' if metric_type == 'l2' else ''\n",
        "\n",
        "index_path = '/content/drive/MyDrive/m3_legal_faiss.index'\n",
        "qa_dataset_path = '/content/drive/MyDrive/law_qa_dataset_validated.json'\n",
        "documents_path = '/content/drive/MyDrive/saudi_laws_scraped.json'\n",
        "\n",
        "print(f\"Using {metric_type.upper()} metric with index: {index_path}\")\n",
        "\n",
        "\n",
        "evaluator_regular = RetrievalEvaluator(\n",
        "    faiss_index_path=index_path,\n",
        "    qa_dataset_path=qa_dataset_path,\n",
        "    documents_path=documents_path,\n",
        "    embeddings_model=retriever_model,\n",
        "    k_values=[1, 3, 5, 10, 20],\n",
        "    metric_type=metric_type,\n",
        "    use_hybrid=False\n",
        ")\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "evaluator_hybrid = RetrievalEvaluator(\n",
        "    faiss_index_path=index_path,\n",
        "    qa_dataset_path=qa_dataset_path,\n",
        "    documents_path=documents_path,\n",
        "    embeddings_model=retriever_model,\n",
        "    k_values=[1, 3, 5, 10, 20],\n",
        "    metric_type=metric_type,\n",
        "    use_hybrid=True,\n",
        "    hybrid_weights=(0.7, 0.3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "05140a1c",
      "metadata": {
        "id": "05140a1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d18f129-478a-480e-d062-57e85200a6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examining QA dataset structure...\n",
            "\n",
            "Dataset keys: ['metadata', 'qa_pairs']\n",
            "\n",
            "Sample QA pair keys: ['id', 'law_name', 'phase', 'category', 'question', 'answer', 'references_ids', 'type', 'selected_articles']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Examining QA dataset structure...\")\n",
        "with open(qa_dataset_path, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "    print(\"\\nDataset keys:\", list(data.keys()))\n",
        "    if 'qa_pairs' in data:\n",
        "        sample_qa = data['qa_pairs'][0]\n",
        "        print(\"\\nSample QA pair keys:\", list(sample_qa.keys()))\n",
        "        if 'references' in sample_qa:\n",
        "            print(\"Sample reference structure:\", type(sample_qa['references']))\n",
        "            if isinstance(sample_qa['references'], list):\n",
        "                print(\"Sample reference keys:\", list(sample_qa['references'][0].keys()))\n",
        "            elif isinstance(sample_qa['references'], dict):\n",
        "                print(\"Sample reference (dict) first item:\", next(iter(sample_qa['references'].items())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8feea8a5",
      "metadata": {
        "id": "8feea8a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "428bfcb6-551c-4efa-cd21-a3fa3c01b193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting evaluation for regular (dense-only) retrieval...\n",
            "Evaluating 4156 queries...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/4156 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100%|██████████| 4156/4156 [03:10<00:00, 21.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation for hybrid retrieval...\n",
            "Evaluating 4156 queries...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4156/4156 [07:19<00:00,  9.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating visualizations...\n",
            "\n",
            "Generating reports...\n",
            "\n",
            "✓ Evaluation completed successfully!\n",
            "\n",
            "======================================================================\n",
            "COMPARISON: Regular (Dense-Only) vs Hybrid (Dense + Sparse) Retrieval\n",
            "======================================================================\n",
            "Metric               Regular         Hybrid          Improvement    \n",
            "----------------------------------------------------------------------\n",
            "Recall@1                0.6025          0.6240          +3.57%\n",
            "Recall@3                0.7386          0.7570          +2.50%\n",
            "Recall@5                0.7813          0.7975          +2.08%\n",
            "Recall@10               0.8338          0.8449          +1.33%\n",
            "Recall@20               0.8721          0.8721          +0.00%\n",
            "\n",
            "Precision@1              0.6112          0.6328          +3.54%\n",
            "Precision@3              0.2517          0.2579          +2.49%\n",
            "Precision@5              0.1603          0.1638          +2.13%\n",
            "Precision@10             0.0859          0.0871          +1.29%\n",
            "Precision@20             0.0450          0.0450          +0.00%\n",
            "\n",
            "MRR                  0.6909          0.7094          +2.69%\n",
            "MAP                  0.6862          0.7051          +2.74%\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting evaluation for regular (dense-only) retrieval...\")\n",
        "metrics_regular, detailed_results_regular = evaluator_regular.evaluate_all()\n",
        "\n",
        "print(\"\\nStarting evaluation for hybrid retrieval...\")\n",
        "metrics_hybrid, detailed_results_hybrid = evaluator_hybrid.evaluate_all()\n",
        "\n",
        "print(\"\\nGenerating visualizations...\")\n",
        "evaluator_regular.plot_metrics(metrics_regular, save_path=f'evaluation_metrics_regular_m3{metric_suffix}.png')\n",
        "evaluator_hybrid.plot_metrics(metrics_hybrid, save_path=f'evaluation_metrics_hybrid_m3{metric_suffix}.png')\n",
        "\n",
        "print(\"\\nGenerating reports...\")\n",
        "\n",
        "\n",
        "report_regular = {\n",
        "    'overall_metrics': {\n",
        "        'recall_at_k': metrics_regular.recall_at_k,\n",
        "        'precision_at_k': metrics_regular.precision_at_k,\n",
        "        'ndcg_at_k': metrics_regular.ndcg_at_k,\n",
        "        'hit_rate_at_k': metrics_regular.hit_rate_at_k,\n",
        "        'mrr': metrics_regular.mrr,\n",
        "        'map': metrics_regular.map_score\n",
        "    },\n",
        "    'metadata': {\n",
        "        'approach': 'regular (dense-only)',\n",
        "        'model': 'BAAI/bge-m3',\n",
        "        'metric_type': metric_type\n",
        "    }\n",
        "}\n",
        "\n",
        "report_hybrid = {\n",
        "    'overall_metrics': {\n",
        "        'recall_at_k': metrics_hybrid.recall_at_k,\n",
        "        'precision_at_k': metrics_hybrid.precision_at_k,\n",
        "        'ndcg_at_k': metrics_hybrid.ndcg_at_k,\n",
        "        'hit_rate_at_k': metrics_hybrid.hit_rate_at_k,\n",
        "        'mrr': metrics_hybrid.mrr,\n",
        "        'map': metrics_hybrid.map_score\n",
        "    },\n",
        "    'metadata': {\n",
        "        'approach': 'hybrid (dense + sparse)',\n",
        "        'model': 'BAAI/bge-m3 + BM25',\n",
        "        'dense_weight': evaluator_hybrid.dense_weight,\n",
        "        'sparse_weight': evaluator_hybrid.sparse_weight,\n",
        "        'metric_type': metric_type\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "with open(f'evaluation_report_regular_m3{metric_suffix}.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(report_regular, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "with open(f'evaluation_report_hybrid_m3{metric_suffix}.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(report_hybrid, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "\n",
        "with open(f'detailed_results_regular_m3{metric_suffix}.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(detailed_results_regular, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "with open(f'detailed_results_hybrid_m3{metric_suffix}.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(detailed_results_hybrid, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\n✓ Evaluation completed successfully!\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARISON: Regular (Dense-Only) vs Hybrid (Dense + Sparse) Retrieval\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Metric':<20} {'Regular':<15} {'Hybrid':<15} {'Improvement':<15}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for k in sorted(metrics_regular.recall_at_k.keys()):\n",
        "    reg_recall = metrics_regular.recall_at_k[k]\n",
        "    hyb_recall = metrics_hybrid.recall_at_k[k]\n",
        "    imp = ((hyb_recall - reg_recall) / reg_recall) * 100 if reg_recall > 0 else 0\n",
        "    print(f\"Recall@{k:<16} {reg_recall:<15.4f} {hyb_recall:<15.4f} {imp:+.2f}%\")\n",
        "\n",
        "print()\n",
        "for k in sorted(metrics_regular.precision_at_k.keys()):\n",
        "    reg_prec = metrics_regular.precision_at_k[k]\n",
        "    hyb_prec = metrics_hybrid.precision_at_k[k]\n",
        "    imp = ((hyb_prec - reg_prec) / reg_prec) * 100 if reg_prec > 0 else 0\n",
        "    print(f\"Precision@{k:<14} {reg_prec:<15.4f} {hyb_prec:<15.4f} {imp:+.2f}%\")\n",
        "\n",
        "print()\n",
        "print(f\"{'MRR':<20} {metrics_regular.mrr:<15.4f} {metrics_hybrid.mrr:<15.4f} {((metrics_hybrid.mrr - metrics_regular.mrr) / metrics_regular.mrr) * 100 if metrics_regular.mrr > 0 else 0:+.2f}%\")\n",
        "print(f\"{'MAP':<20} {metrics_regular.map_score:<15.4f} {metrics_hybrid.map_score:<15.4f} {((metrics_hybrid.map_score - metrics_regular.map_score) / metrics_regular.map_score) * 100 if metrics_regular.map_score > 0 else 0:+.2f}%\")\n",
        "print(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a0297636a88043d5bbbdbf553ee8fa50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0112d18c830448e885c062c33eb3a620",
              "IPY_MODEL_f04d039a64b1451fa26978a97922715c",
              "IPY_MODEL_522b147bac6c4763adeb06f181bf73b4"
            ],
            "layout": "IPY_MODEL_6bb4e8ad89ba47d085108cae8d5dcfd5"
          }
        },
        "0112d18c830448e885c062c33eb3a620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d7337f93bd1433088cf374cdbf85083",
            "placeholder": "​",
            "style": "IPY_MODEL_a5800e881ca34d09b59a7fa2844864f9",
            "value": "Fetching 30 files: 100%"
          }
        },
        "f04d039a64b1451fa26978a97922715c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63f6e88da29b474d8d00955aa07030e4",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2cd375ecc9f47e29b72ee076ccf8f7c",
            "value": 30
          }
        },
        "522b147bac6c4763adeb06f181bf73b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fce852996b94211b25d059ed4845cae",
            "placeholder": "​",
            "style": "IPY_MODEL_550bd9f29fc54a5ebd05286105dfe087",
            "value": " 30/30 [00:00&lt;00:00, 2222.70it/s]"
          }
        },
        "6bb4e8ad89ba47d085108cae8d5dcfd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d7337f93bd1433088cf374cdbf85083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5800e881ca34d09b59a7fa2844864f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63f6e88da29b474d8d00955aa07030e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2cd375ecc9f47e29b72ee076ccf8f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fce852996b94211b25d059ed4845cae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550bd9f29fc54a5ebd05286105dfe087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}